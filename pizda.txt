\documentclass[12pt, a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath, amsfonts}

\date{Февраль 2022}

\begin{document}
%\maketitle

\section*{2.}

На доске будет записан НОД всех исходных чисел. Докажем это.
$$ \text{НОД}(a, b, c) =  \text{НОД}(\text{НОД}(a, b), c).$$
Докажем это. Действительно, пусть
$$a = a_1d = a_2rd,\ b = b_2d = b_2rd,\ c = c_1d,\ d = \text{НОД}(a, b, c),\ rd = \text{НОД}(a, b),$$
тогда
$$\text{НОД}(\text{НОД}(a, b), c) = \text{НОД}(rd, c_1d) = d.$$
Аналогично в случае большего количества чисел можно представить их так:
$$a_1 = a'_1r_{n-1}r_{n-2}\dots r_1,\ a_2 = a'_2r_{n-1}r_{n-2}\dots r_1,\ a_3 = a'_3r_{n-2}r_{n-3}\dots r_1,\dots,a_n = a'_nr_1,$$
где
$$r_1 = \text{НОД}(a_1, a_2,\dots, a_n),$$
$$r_1r_2 = \text{НОД}(a_1, a_2,\dots, a_{n-1}),$$
$$\dots ,$$
$$r_1r_2\dots r_{n-2} = \text{НОД}(a_1, a_2, a_3),$$
$$r_1r_2\dots r_{n-1} = \text{НОД}(a_1, a_2),$$
и аналогично
$$\text{НОД}(\text{НОД}(\dots (\text{НОД}(\text{НОД}(a_1, a_2), a_3),\dots ,)a_{n-1}), a_n) = \text{НОД}(a_1, a_2,\dots , a_n).$$ 
Шаг алгоритма представляет собой шаг алгоритма Евклида, и он сохраняет НОД тех двух чисел, на которые подействовал, а значит, по доказанному, и НОД всех записанных на доске чисел. Алгоритм Евклида завершается, когда 2 числа становятся равны (они становятся равны своему НОД); данный же алгоритм завершится, когда все числа станут равны своему НОД.

\section*{4.}

Известно, что $ab = \text{НОД}(a, b)\text{НОК}(a, b)$.
\\Алгоритм будет иметь вид:
\\1. Найти НОД$(a, b)$ по алгоритму Евклида;
\\2. Найти $ab$;
\\3. Найти НОК$(a, b) = \frac{ab}{\text{НОД}(a,b)}.$
\\Алгоритм работает за $O(n^3)$. Докажем это.
\\Умножение, выполняемое по алгоритму Multiply (ДПВ, рис. 1.1) работает за $O(n^2)$: выполняется $n$ рекурсивных вызовов, на каждом из них 2 сдвига/2 сдвига, сложение - $O(n)$ операций; всего $O(n^2)$ операций.
\\Произведение двух $n$-битовых чисел будет не более, чем $2n$-битовым числом. Докажем это.
\\Рассмотрим наибольшее возможное $n$-битовое число. Оно равно $2^n - 1$. Его квадрат будет равен $2^{2n} - 2 \cdot 2^n + 1$, это $2n$-битовое число.
\\Деление, выполняемое по алгоритму Divide (ДПВ, рис. 1.2) работает за $O(n^2)$ (доказано в задании 3). Тогда деление не более чем $2n$-битового числа на не более чем $2n$-битовое (на самом деле $n$-битовое, но $n < 2n$) число будет работать за $O(4n^2)$, т.е. за $O(n^2)$.
\\Алгоритм Евклида работает за $O(n^3)$ Докажем это.
\\За 2 шага алгоритма мы переходим от работы с $n$-битовыми числами к работе с не более чем $(n - 1)$-битовыми. Действительно, пусть $a < b$, тогда если $a < \frac{b}{2}$, то число $a$ будет не более чем $(n - 1)$-битовым, $b$ mod $a < a < \frac{b}{2}$ - не более чем $(n - 1)$-битовым; иначе, если $a > \frac{b}{2}$ (может быть $n$-битовым), то $b$ mod $a = b - a < \frac{b}{2}$ - не более чем $(n - 1)$-битовое. Итак, за 1 шаг большее число становится короче как минимум на 1 бит. Тогда спустя 2 шага мы работаем с двумя не более чем $(n - 1)$-битовыми числами.
\\Всего шагов будет не более чем $2n$ (если большее число на каждом шаге уменьшается ровно на 1 бит). Тогда можем сказать, что имеем не более чем $n$ пар шагов, в $i$-й паре дважды выполняется действие с $i$-битовыми числами (на самом деле один раз с двумя $i$-битовыми и один раз с $i$-битовым и $(i - 1)$-битовым, но действие с $i$-битовым и $(i - 1)$-битовым занимает по времени столько же, сколько с двумя $i$-битовыми числами).
\\Каждое действие - это взятие остатка, работает как алгоритм Divide, т.е. за $O(i^2)$.
\\Тогда алгоритм Евклида работает за 
$$\sum_{i=1}^{n}2i^2 = \sum_{i=0}n2i^2 = \frac{2}{3}n^3 = O(n^3).$$
Тогда весь алгоритм будет работать за
$$O(n^3)+O(n^2)+O(n^2)=O(n^3).$$

\section*{5.}

Для нашего алгоритма понадобится 2 массива ($a[i]$ - для входных данных, $b[i]$ - для хранения результатов промежуточных вычислений) и 2 переменные: $sum$ - для хранения суммы, $i$ - счетчик.
\\Алгоритм будет иметь вид:
\begin{verbatim}
sum = 0;
for(i = 1; i <= n; i++)
{
sum = sum + a[i];
}
for(i = 1; i <= n; i++)
{
b[i] = sum - a[i];
}
for(i = 1; i <= n; i++)
{
b[i] = b[i] * a[i];
}
sum = 0;
for(i = 1; i <= n; i++)
{
sum = sum + b[i];
}
sum = sum/2
\end{verbatim} 

\\Докажем корректность. 
\\Действительно,
$$\sum_{i\neq j}a_ia_j = a_1a_2 + a_1a_3 + \dots +a_1a_n + a_2a_3 + \dots +a_2a_n + a_3a_4 + \dots + a_{n - 1}a_n = \frac{1}{2} \sum_{i=1}^{n}a_i(\sum_{j=1}^{n}a_j - a_i).$$
Первый цикл вычисляет
$$\sum_{j=1}^{n}a_j.$$
Второй цикл записывает в каждую $b[i]$ число, равное
$$\sum_{j=1}^{n}a_j - a_i.$$
Третий цикл записывает в каждую $b[i]$ число, равное
$$a_i(\sum_{j=1}^{n}a_j - a_i).$$
Четвертый цикл вычисляет
$$\sum_{i=1}^{n}a_i(\sum_{j=1}^{n}a_j - a_i).$$
И, наконец, строка после всех циклов вычисляет
$$\frac{1}{2}\sum_{i=1}^{n}a_i(\sum_{j=1}^{n}a_j - a_i).$$
При пустом входе алгоритм выдает 0, при входе из 1 элемента - также 0.
\\Докажем линейность.
\\Действительно, считать массив - это $n$ операций, в каждом цикле выполняется $n$ операций, всего 4 цикла и еще 3 операции, итого $5n + 3 = O(n)$ операций.
чтд.


\section*{6.}
\subsection*{a)}

$$T(n)=36T(\frac{n}{6}) + n^2$$
$$d = log_6 36 = 2$$
$$n^2=\Theta(n^2) = \Theta(n^d) \Rightarrow $$
$$T(n) = \Theta(n^2 \log n) $$
по основной теореме о рекурсии.

\subsection*{б)}

$$T(n)=3T(\frac{n}{3}) + n^2$$
$$d = \log_3 3 = 1$$
$$\exists \varepsilon = 1 > 0 : n^2 = \Omega(n^2) = \Omega(n^{d + \varepsilon}); $$
$$\exists0 < c = \frac{1}{2} < 1, N = 3 : \forall n \geq N\ 3(\frac{n}{3})^2 = \frac{n^2}{3} < cn^2 \Rightarrow$$
$$T(n) = \Theta(n^2)$$
по основной теореме о рекурсии.

\subsection*{в)}

$$T(n) = 4T(\frac{n}{2}) + \frac{n}{\log n}$$
$$d = \log_2 4 = 2$$
$$\exists \varepsilon = 1 > 0 : \frac{n}{\log n} = O(n) = O(n^{d - \varepsilon}) \Rightarrow$$
$$T(n) = \Theta(n^2)$$
по основной теореме о рекурсии.


\section*{9.}
\subsection*{б)}

$$T(n) = T(\lfloor \alpha n \rfloor) + T(\lfloor(1 - \alpha) n \rfloor) + \Theta(n) (0 < \alpha < 1) $$
Рассмотрим дерево рекурсии. На $i$-м уровне (начинаем считать с нуля; уровень определяем так: 2 вершины, порожденные нулевым уровнем - первый уровень; 4 вершины, порожденные первым уровнем - второй уровень; и т.д.) мы будем иметь, если рассматривать все вершины уровня, $T$ от каждого слагаемого из ($\alpha + (1 - \alpha))^i n$, если разбивать слагаемые с коэффициентами, не равными единице, по единице (т.е. не одна вершина, где вызывается $T(2\alpha(1 - \alpha)n)$, а 2 вершины, в каждой из которых вызывается $T(\alpha(1 - \alpha)n)$).
\\Тогда на $i$-м уровне будет $2^i$ вершин. Пусть $\beta_{ij}$ - такое число (вообще зависящее от $\alpha$), что в $j$-й вершине $i$-го уровня вызывается $T(\beta_{ij}n) \Rightarrow$ выполняется $\Theta(\beta_{ij}n)$ операций. Но
$$ \sum_{j=1}^{2^i} \beta_{ij} = (\alpha + (1 - \alpha))^i = (\alpha + 1 - \alpha)^i = 1^i = 1 \Rightarrow$$
на каждом уровне (для достаточно больших $\beta_{ij}n$, т.е. пока $T(\beta_{ij}n) \neq O(1))$, выполняется $\Theta(n) $ операций.
\\Пусть для определенности $0 < \alpha \leq \frac{1}{2}$ (случай, когда $1 > \alpha \geq \frac{1}{2}$, рассматривается аналогично, т.к. на всех этапах перестановка $\alpha$ и $1 - \alpha$ ничего не меняет). Тогда высота дерева
$$h = - \log_\alpha n$$
(знак «-» потому, что $\alpha < 1 \Rightarrow \log_\alpha n < 0$).
\\Т.к. на нижнем уровне $2^{-\log_\alpha n} = \Theta(n)$ вершин, в каждой из которых выполняется $\Theta(1)$ операций, т.е. всего на уровне $\Theta(n)$ операций, то во всем дереве выполнится не более
$$ \sum_{i=0}^{-\log_\alpha n - 1} \Theta(n) + \Theta(n) = \Theta (n) \sum_{i=0}^{-\log_\alpha n - 1} 1 + \Theta(n) = \Theta(n \log n) + \Theta(n) = \Theta(n \log n)$$
операций.
\\Ответ: $\Theta(n \log n)$.

\subsection*{в)}

$$T(n) = T(\lfloor\frac{n}{2}\rfloor) + 2T (\lfloor \frac{n}{4} \rfloor) + \Theta(n)$$
Оценим функцию снизу.
$$T(n) > 4T(\lfloor \frac{n}{4} \rfloor) + \Theta(n)$$
Это оценка снизу. Докажем это.
\\Пусть $i$-й уровень - все вершины, где вызывается $T(\lfloor\frac{n}{2^i}\rfloor)$, а $\#_i$ - число вершин на этом уровне. Тогда у исходной функции
$$\#_i = \#_{i - 1} + 2\#_{i - 2} \text{ при } i > 1;\ \#_0 = \#_1 = 1$$
Тогда
$$\forall i \ \#_i + \#_{i - 1} = 2(\#_{i - 1} + \#_{i - 2})$$
Т.к. $\#_0 + \#_1 = 2$, то $\#_1 + \#_2 = 4$ и т.д. $\#_{i - 1} + \#_i = 2^i$. Значит, на каждом $2i$-м и предшествующем ему $(2i - 1)$-м уровне будет суммарно $2^{2i}$ вершин.
\\У нашей «оценки снизу» будет $2^{2i}$ вершин на каждом четном уровне, нечетные же уровни будут пусты. Тогда на каждом четном и предшествующем ему нечетном уровне (пустом) будет выполняться суммарно
$$2^{2i}\Theta(\frac{n}{2^{2i}}) = \Theta(n)$$
операций.
\\У исходной же функции на каждом четном и предшествующем ему нечетном уровне (непустом) будет выполняться суммарно
$$A\Theta(\frac{n}{2^{2i - 1}}) + (2^{2i} - A)\Theta(\frac{n}{2^{2i}}) > A\Theta(\frac{n}{2^{2i}}) + (2^{2i} - A)\Theta(\frac{n}{2^{2i}}) = 2^{2i}\Theta(\frac{n}{2^{2i}})$$
операций, где $A \in \mathbb{R}, A < 2^{2i}$.
\\Известно, что числа Фибоначчи растут экспоненциально; $\#_k$ растет быстрее чисел Фибоначчи, но медленнее, чем $2^k$, т.е. также экспоненциально; последовательность чисел вершин на каждом четном уровне «оценки снизу» также растет экспоненциально. Т.к. высота обоих деревьев выражается как $\Theta(\log n)$, то крона каждого из них вносит вклад $\Theta(n)$ в общую асимптотику.
\\Значит, и всего в нашей «оценке снизу» выполнится асимптотически не более, чем в исходной функции, операций, и это действительно оценка снизу.
\\Для нижней оценки дерево рекурсии будет иметь вид: из каждой вершины выходит 4 вершины; на $i$-м уровне выполняется
$$4^i\Theta(\frac{n}{4^i}) = \Theta(n)$$
операций; высота дерева
$$h = \log_4 n.$$
\\
$$ f(i) = \Theta(n) \Rightarrow \exists C_1 > 0 : f(i) \geq C_2 n \Rightarrow$$
т.к. на нижнем уровне $4^{\log_4 n} = n$ вершин, в каждой из которых выполняется $\Theta(1)$ операций, т.е. всего на уровне $\Theta(n)$ операций, то во всем дереве выполнится не менее
$$\sum_{i=0}^{\log_4 n - 1}C_1 n + \Theta(n) = C_1 n \log n + \Theta(n) = \Theta(n \log n)$$
операций.
\\Оценим функцию сверху.
$$T(n) < 2T(\lfloor \frac{n}{2}\rfloor) + \Theta(n)$$
Это оценка сверху, т.к. тогда на каждом уровне, где выполняется $T(\frac{n}{2^i})$, имеем $2^i$ вершин; в исходном же дереве их будет меньше. Для верхней оценки дерево рекурсии будет иметь вид: из каждой вершины выходит 2 вершины; на $i$-м уровне выполняется
$$\Theta(2^i\frac{n}{2^i}) = \Theta(n).$$
операций; высота дерева
$$h = \log_2 n.$$
$$f(i) = \Theta(n) \Rightarrow \exists C_2 > 0 : f(i) \leq C_2 n \Rightarrow$$
т.к. на нижнем уровне $2^{\log_2 n} = n$ вершин, в каждой из которых выполняется $\Theta(1)$ операций, т.е. всего на уровне $\Theta(n)$ операций, то во всем дереве выполнится не более
$$\sum_{i=0}^{\log_2 n - 1} C_2 n + \Theta(n) = C_2 n \log n + \Theta(n) = \Theta(n \log n)$$
операций.

\subsection*{г)}

$$T(n)=27T(\frac{n}{3}) + \frac{n^3}{\log^2 n}$$
Рассмотрим дерево рекурсии. На каждом шаге рекурсии количество вершин увеличивается в 27 раз; на $i$-м шаге в каждой вершине выполняется
$$\frac{(\frac{n}{3^i})^3}{\log^2 \frac{n}{3^i}}$$
операций. Тогда всего на $i$-м шаге выполняется
$$27^i \frac{(\frac{n}{3^i})^3}{\log^2 \frac{n}{3^i}} = 3^{3i} \frac{n^3}{3^{3i} \log^2 \frac{n}{3^i}} = \frac{n^3}{\log^2 \frac{n}{3^i}}$$
операций.
\\Высота дерева составляет
$$h = \log_3 n.$$
Оценим асимптотику снизу.
$$\frac{n}{3^i} \leq n \Rightarrow \log \frac{n}{3^i} \leq \log n \Rightarrow \log^2 \frac{n}{3^i} \leq \log^2 n \Rightarrow \frac{n^3}{\log^2 \frac{n}{3^i}} \geq \frac{n^3}{\log^2 n} \Rightarrow$$
$$\sum_{i=0}^{\log_3 n - 1} \frac{n^3}{\log^2 \frac{n}{3^i}} \geq  \sum_{i=0}^{\log_3 n - 1} \frac{n^3}{\log^2 n} = \frac{n^3}{\log n}.$$


\section*{11.}
\subsection*{1)}

Найдем оценку сверху.
\\На каждом следующем уровне ($i$-й уровень - совокупность всех вершин, где вызывается $T(\lceil \frac{n}{2^i} \rceil)$) будет в $2^i$ раз больше вершин, чем на предыдущем, а значит, на $i$-м уровне будет выполняться
$$\frac{n^i}{\Pi_{j=0}^{i - 1} 2^j} \Theta(\frac{n}{2^i}) = \Theta (\frac{n^{i + 1}}{\Pi_{j=0}^{i} 2^j}) = \Theta (\frac{n^{i+1}}{2^{\sum_{j=0}^{i} j}}) = \Theta (\frac{n^{i + 1}}{2^{\frac{i(i + 1)}{2}}}) = \Theta ((\frac{n}{2})^{i + 1} \frac{1}{2^{\frac{(i - 1)(i + 1)}{2}}}) = $$
$$= \Theta((\frac{n}{2})^{i + 1} \frac{1}{2^{\frac{i^2 - 1}{2}}})$$
операций.
\\Высота дерева рекурсии
$$h = \log_2 n.$$
Тогда всего будет выполняться
$$\sum_{i = 0}^{\log_2 n -1} \Theta(\frac{n^{i+1}}{2^{\frac{i(i + 1)}{2}}}) < \sum_{i = 0}^{\log_2 n} \Theta(\frac{n^{i+1}}{2^i}) = n \sum_{i = 0}^{\log_2 n} \Theta ((\frac{n}{2})^i).$$


\end{document}
